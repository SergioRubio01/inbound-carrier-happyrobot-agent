"""add_call_metrics_table

Revision ID: 034e2428cb92
Revises: 909554643437
Create Date: 2025-08-21 16:21:48.400715

"""

from typing import Sequence, Union

import sqlalchemy as sa
from alembic import op
from sqlalchemy.dialects import postgresql

# Import UUID type for proper type checking
try:
    from sqlalchemy.dialects.postgresql import UUID
except ImportError:
    UUID = sa.String  # type: ignore

# revision identifiers, used by Alembic.
revision: str = "034e2428cb92"
down_revision: Union[str, None] = "909554643437"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    connection = op.get_bind()
    inspector = sa.inspect(connection)

    # Only create call_metrics table if it doesn't exist
    if "call_metrics" not in inspector.get_table_names():
        op.create_table(
            "call_metrics",
            sa.Column("metrics_id", postgresql.UUID(as_uuid=True), nullable=False),
            sa.Column("transcript", sa.Text(), nullable=False),
            sa.Column("response", sa.String(length=50), nullable=False),
            sa.Column("reason", sa.Text(), nullable=True),
            sa.Column(
                "final_loadboard_rate", sa.NUMERIC(precision=10, scale=2), nullable=True
            ),
            sa.Column("session_id", sa.String(length=100), nullable=True),
            sa.Column(
                "created_at",
                sa.DateTime(timezone=True),
                server_default=sa.text("now()"),
                nullable=False,
            ),
            sa.Column(
                "updated_at",
                sa.DateTime(timezone=True),
                server_default=sa.text("now()"),
                nullable=False,
            ),
            sa.PrimaryKeyConstraint("metrics_id"),
        )
        op.create_index(
            "idx_call_metrics_session_id", "call_metrics", ["session_id"], unique=False
        )

    # First check if the tables and columns exist before trying to drop them

    # Check if negotiations table exists before trying to access it
    if "negotiations" in inspector.get_table_names():
        # Check if negotiations table has call_id column
        negotiations_columns = [
            col["name"] for col in inspector.get_columns("negotiations")
        ]

        if "call_id" in negotiations_columns:
            # Check for and drop index if it exists
            negotiations_indexes = [
                idx["name"] for idx in inspector.get_indexes("negotiations")
            ]
            if "ix_negotiations_call_id" in negotiations_indexes:
                op.drop_index(
                    op.f("ix_negotiations_call_id"), table_name="negotiations"
                )

            # Check for and drop foreign key if it exists
            negotiations_fkeys = inspector.get_foreign_keys("negotiations")
            for fkey in negotiations_fkeys:
                if "call_id" in fkey["constrained_columns"] and fkey["name"]:
                    op.drop_constraint(fkey["name"], "negotiations", type_="foreignkey")

            # Drop the column
            op.drop_column("negotiations", "call_id")

    # Check if calls table exists before trying to drop it
    if "calls" in inspector.get_table_names():
        # Drop indexes if they exist
        calls_indexes = [idx["name"] for idx in inspector.get_indexes("calls")]
        indexes_to_drop = [
            "ix_calls_caller_phone",
            "ix_calls_carrier_id",
            "ix_calls_end_time",
            "ix_calls_external_call_id",
            "ix_calls_follow_up_required",
            "ix_calls_load_id",
            "ix_calls_mc_number",
            "ix_calls_outcome",
            "ix_calls_sentiment",
            "ix_calls_start_time",
            "ix_calls_transferred_to_human",
        ]

        for index_name in indexes_to_drop:
            if index_name in calls_indexes:
                op.drop_index(op.f(index_name), table_name="calls")

        # Drop the table
        op.drop_table("calls")
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column(
        "negotiations",
        sa.Column(
            "call_id", postgresql.UUID(as_uuid=True), autoincrement=False, nullable=True
        ),
    )
    op.create_foreign_key(
        op.f("negotiations_call_id_fkey"),
        "negotiations",
        "calls",
        ["call_id"],
        ["call_id"],
    )
    op.create_index(
        op.f("ix_negotiations_call_id"), "negotiations", ["call_id"], unique=False
    )
    op.create_table(
        "calls",
        sa.Column(
            "call_id",
            postgresql.UUID(as_uuid=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "external_call_id",
            sa.VARCHAR(length=100),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "session_id", sa.VARCHAR(length=100), autoincrement=False, nullable=True
        ),
        sa.Column(
            "mc_number", sa.VARCHAR(length=20), autoincrement=False, nullable=True
        ),
        sa.Column(
            "carrier_id",
            postgresql.UUID(as_uuid=True),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "caller_phone", sa.VARCHAR(length=20), autoincrement=False, nullable=True
        ),
        sa.Column(
            "caller_name", sa.VARCHAR(length=100), autoincrement=False, nullable=True
        ),
        sa.Column(
            "load_id", postgresql.UUID(as_uuid=True), autoincrement=False, nullable=True
        ),
        sa.Column(
            "multiple_loads_discussed",
            postgresql.ARRAY(postgresql.UUID(as_uuid=True)),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "start_time",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "end_time",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("duration_seconds", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "call_type", sa.VARCHAR(length=30), autoincrement=False, nullable=False
        ),
        sa.Column("channel", sa.VARCHAR(length=30), autoincrement=False, nullable=True),
        sa.Column(
            "agent_type", sa.VARCHAR(length=30), autoincrement=False, nullable=True
        ),
        sa.Column(
            "agent_id", sa.VARCHAR(length=50), autoincrement=False, nullable=True
        ),
        sa.Column(
            "outcome", sa.VARCHAR(length=50), autoincrement=False, nullable=False
        ),
        sa.Column(
            "outcome_confidence",
            sa.NUMERIC(precision=3, scale=2),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "sentiment", sa.VARCHAR(length=20), autoincrement=False, nullable=True
        ),
        sa.Column(
            "sentiment_score",
            sa.NUMERIC(precision=3, scale=2),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "sentiment_breakdown",
            postgresql.JSONB(),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "initial_offer",
            sa.NUMERIC(precision=10, scale=2),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "final_rate",
            sa.NUMERIC(precision=10, scale=2),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("rate_accepted", sa.BOOLEAN(), autoincrement=False, nullable=True),
        sa.Column(
            "extracted_data",
            postgresql.JSONB(),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("transcript", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("transcript_summary", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column(
            "key_points",
            postgresql.ARRAY(sa.TEXT()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "transferred_to_human", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "transfer_reason",
            sa.VARCHAR(length=100),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "transferred_at",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "assigned_rep_id", sa.VARCHAR(length=50), autoincrement=False, nullable=True
        ),
        sa.Column(
            "follow_up_required", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column("follow_up_reason", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column(
            "follow_up_deadline",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "follow_up_completed", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column("recording_url", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column(
            "recording_duration_seconds",
            sa.INTEGER(),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("quality_score", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "quality_issues",
            postgresql.ARRAY(sa.TEXT()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "created_by", sa.VARCHAR(length=100), autoincrement=False, nullable=True
        ),
        sa.Column("version", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["carrier_id"], ["carriers.carrier_id"], name=op.f("calls_carrier_id_fkey")
        ),
        sa.ForeignKeyConstraint(
            ["load_id"], ["loads.load_id"], name=op.f("calls_load_id_fkey")
        ),
        sa.PrimaryKeyConstraint("call_id", name=op.f("calls_pkey")),
    )
    op.create_index(
        op.f("ix_calls_transferred_to_human"),
        "calls",
        ["transferred_to_human"],
        unique=False,
    )
    op.create_index(op.f("ix_calls_start_time"), "calls", ["start_time"], unique=False)
    op.create_index(op.f("ix_calls_sentiment"), "calls", ["sentiment"], unique=False)
    op.create_index(op.f("ix_calls_outcome"), "calls", ["outcome"], unique=False)
    op.create_index(op.f("ix_calls_mc_number"), "calls", ["mc_number"], unique=False)
    op.create_index(op.f("ix_calls_load_id"), "calls", ["load_id"], unique=False)
    op.create_index(
        op.f("ix_calls_follow_up_required"),
        "calls",
        ["follow_up_required"],
        unique=False,
    )
    op.create_index(
        op.f("ix_calls_external_call_id"), "calls", ["external_call_id"], unique=False
    )
    op.create_index(op.f("ix_calls_end_time"), "calls", ["end_time"], unique=False)
    op.create_index(op.f("ix_calls_carrier_id"), "calls", ["carrier_id"], unique=False)
    op.create_index(
        op.f("ix_calls_caller_phone"), "calls", ["caller_phone"], unique=False
    )
    op.drop_index("idx_call_metrics_session_id", table_name="call_metrics")
    op.drop_table("call_metrics")
    # ### end Alembic commands ###
